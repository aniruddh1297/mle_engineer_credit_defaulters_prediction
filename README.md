# ğŸ§  Credit Card Default Prediction using Azure Machine Learning

## ğŸ“Œ Overview

This project builds a **production-grade ML pipeline** to predict whether a credit card client will default on their next payment. The solution uses **Azure Machine Learning SDK v2**, applies **MLOps best practices**, and supports **CI/CD, explainability, automated deployment**, and **cost-sensitive evaluation**.

## ğŸ’¼ Business Problem

Defaulting credit card customers significantly impact financial institutions. Accurately identifying high-risk clients enables the bank to take preventive action. This model predicts defaults using customer behavior and credit profile.

## ğŸ—ï¸ Architecture

- Azure ML SDK v2 + MLFlow
- Multi-component SDK pipeline: preprocess â†’ train â†’ evaluate
- Cross-environment setup: dev, test, prod workspaces
- Model promotion strategy from test â†’ prod
- Automated deployment via Azure Online Endpoints
- CI/CD with GitHub Actions (includes conditional triggers for dev/test/prod)
- Environment and component registration handled programmatically

## ğŸ“ Project Structure

```
.  
â”œâ”€â”€ .azureml/                         
â”‚   â”œâ”€â”€ config.dev.json
â”‚   â”œâ”€â”€ config.test.json
â”‚   â””â”€â”€ config.prod.json
â”œâ”€â”€ .github/workflows/               
â”‚   â””â”€â”€ azureml-pipeline-ci.yml
â”œâ”€â”€ component_code/                  
â”‚   â”œâ”€â”€ evaluate/
â”‚   â”œâ”€â”€ preprocess/
â”‚   â””â”€â”€ train/
â”œâ”€â”€ config/                          
â”‚   â”œâ”€â”€ compute.yaml
â”‚   â””â”€â”€ environment.yaml
â”œâ”€â”€ data/                            
â”œâ”€â”€ doc/                             
â”œâ”€â”€ pipeline/                        
â”‚   â””â”€â”€ run_pipeline.py
â”œâ”€â”€ promote_scripts/                
â”‚   â””â”€â”€ promote_model.py
â”œâ”€â”€ register_scripts/               
â”‚   â”œâ”€â”€ data_upload.py
â”‚   â”œâ”€â”€ register_component.py
â”‚   â”œâ”€â”€ register_compute.py
â”‚   â””â”€â”€ register_env.py
â”œâ”€â”€ serve/                           
â”œâ”€â”€ src(for_local_test)/            
â”œâ”€â”€ utils/                           
â”œâ”€â”€ .env                             
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt                 
```

## ğŸ§ª ML Pipeline Components

- **Preprocessing**: Scales data, handles missing values
- **Training**: Trains XGBoost, Logistic Regression, Random Forest; logs best model via MLflow
- **Evaluation**:
  - Classification metrics (F1, ROC-AUC, Precision/Recall)
  - Cost-sensitive threshold optimization
  - SHAP explainability
  - Confusion matrix & curves logged to MLflow

## ğŸš€ Deployment

- `score.py`: Inference script using MLflow
- `deploy_endpoint.py`: Script to deploy endpoint
- `inference_config.yaml`: Configuration for endpoint creation
- `sample_request.json`: Test payload

```bash
curl -X POST <ENDPOINT_URL> -H "Authorization: Bearer <TOKEN>" -d @sample_request.json
```

## ğŸ” Model Promotion Strategy

- Models are registered in the **test workspace** and evaluated.
- If they pass performance thresholds:
  - Promoted via `promote_model.py` to **prod**
  - Deployed automatically if `prod-run` is used in commit message

## âœ… CI/CD with GitHub Actions

Automates:
- Component and environment registration
- Pipeline trigger (conditional)
- Model promotion and deployment

Trigger conditions:
- `pipeline-start`: forces dev pipeline run
- `prod-run`: full pipeline run and deploy in prod
- Otherwise:
  - Dev: no-op
  - Test: always runs
  - Main: only promotes

```yaml
on:
  push:
    branches:
      - release/dev
      - release/test
      - main
```

## ğŸ“ˆ Model Performance

| Metric       | Value   |
|--------------|---------|
| Accuracy     | 77.1%   |
| F1 Score     | 55.1%   |
| ROC-AUC      | 76.5%   |
| Precision    | 48.6%   |
| Recall       | 56.8%   |
| Threshold    | 0.69    |
| Cost Estimate| ~â‚¬764K  |

## ğŸ§  Explainability

SHAP values highlight feature contributions. Logged:
- `shap_beeswarm.png`
- ROC/PR curves
- Confusion matrix heatmap

## ğŸ”’ Cost & Security

- Threshold optimized using cost matrix (FP: â‚¬1,000, FN: â‚¬900)
- Uses small instances (`Standard_E2s_v3`)
- Secure token-based deployment via Azure and GitHub secrets

## â–¶ï¸ Running Locally

```bash
pip install -r requirements.txt
az login
```

```bash
python register_scripts/register_env.py --env dev
python register_scripts/register_component.py --env dev
python register_scripts/data_upload.py --env dev
python pipeline/run_pipeline.py --env dev
```

To deploy:
```bash
cd serve
python deploy_endpoint.py --env prod
```

## ğŸ§ª Endpoint Test

```bash
curl -X POST <URL> -H "Authorization: Bearer <TOKEN>" -d @serve/sample_request.json
```

## ğŸ™Œ Acknowledgments

- Azure Machine Learning SDK v2
- MLflow for experiment tracking
- GitHub Actions for DevOps automation
- scikit-learn, XGBoost, SHAP